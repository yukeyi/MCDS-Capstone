{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2000, 'val': 200}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, mask]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform=trans)\n",
    "val_set = SimDataset(200, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 192, 192]) torch.Size([25, 6, 192, 192])\n",
      "-2.117904 2.64 -1.8858967 0.6714393\n",
      "0.0 1.0 0.004654948 0.06806831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10ff0c780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d(kernel_size=7, stride=7, padding=0),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "summary(base_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "             ReLU-25          [-1, 128, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "           Conv2d-28          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-31          [-1, 128, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "           Conv2d-44          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-47          [-1, 256, 14, 14]               0\n",
      "           Conv2d-48          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-49          [-1, 256, 14, 14]             512\n",
      "             ReLU-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-52          [-1, 256, 14, 14]             512\n",
      "             ReLU-53          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-54          [-1, 256, 14, 14]               0\n",
      "           Conv2d-55            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-56            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-57            [-1, 512, 7, 7]               0\n",
      "           Conv2d-58            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-59            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-60            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-63            [-1, 512, 7, 7]               0\n",
      "           Conv2d-64            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-65            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-66            [-1, 512, 7, 7]               0\n",
      "           Conv2d-67            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-68            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-69            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-70            [-1, 512, 7, 7]               0\n",
      "           Conv2d-71            [-1, 512, 7, 7]         262,656\n",
      "             ReLU-72            [-1, 512, 7, 7]               0\n",
      "         Upsample-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]          65,792\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 512, 14, 14]       3,539,456\n",
      "             ReLU-77          [-1, 512, 14, 14]               0\n",
      "         Upsample-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          16,512\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 256, 28, 28]       1,474,816\n",
      "             ReLU-82          [-1, 256, 28, 28]               0\n",
      "         Upsample-83          [-1, 256, 56, 56]               0\n",
      "           Conv2d-84           [-1, 64, 56, 56]           4,160\n",
      "             ReLU-85           [-1, 64, 56, 56]               0\n",
      "           Conv2d-86          [-1, 256, 56, 56]         737,536\n",
      "             ReLU-87          [-1, 256, 56, 56]               0\n",
      "         Upsample-88        [-1, 256, 112, 112]               0\n",
      "           Conv2d-89         [-1, 64, 112, 112]           4,160\n",
      "             ReLU-90         [-1, 64, 112, 112]               0\n",
      "           Conv2d-91        [-1, 128, 112, 112]         368,768\n",
      "             ReLU-92        [-1, 128, 112, 112]               0\n",
      "         Upsample-93        [-1, 128, 224, 224]               0\n",
      "           Conv2d-94         [-1, 64, 224, 224]         110,656\n",
      "             ReLU-95         [-1, 64, 224, 224]               0\n",
      "           Conv2d-96          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 17,800,134\n",
      "Trainable params: 17,800,134\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 354.87\n",
      "Params size (MB): 67.90\n",
      "Estimated Total Size (MB): 423.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0/14\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "        \n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
